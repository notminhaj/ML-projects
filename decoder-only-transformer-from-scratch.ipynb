{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T00:11:42.118245Z","iopub.execute_input":"2024-07-23T00:11:42.118608Z","iopub.status.idle":"2024-07-23T00:11:43.154213Z","shell.execute_reply.started":"2024-07-23T00:11:42.118576Z","shell.execute_reply":"2024-07-23T00:11:43.153216Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# the guide:\n# https://www.youtube.com/watch?v=C9QSpl5nmrY&t=23s&ab_channel=StatQuestwithJoshStarmer","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:11:43.156043Z","iopub.execute_input":"2024-07-23T00:11:43.156478Z","iopub.status.idle":"2024-07-23T00:11:43.160572Z","shell.execute_reply.started":"2024-07-23T00:11:43.156451Z","shell.execute_reply":"2024-07-23T00:11:43.159523Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## First, check to see if lightning is installed, if not, install it.\nimport pip\ntry:\n  __import__(\"lightning\")\nexcept ImportError:\n  pip.main(['install', \"lightning\"])  \n\nimport torch ## torch let's us create tensors and also provides helper functions\nimport torch.nn as nn ## torch.nn gives us nn.Module(), nn.Embedding() and nn.Linear()\nimport torch.nn.functional as F # This gives us the softmax() and argmax()\nfrom torch.optim import Adam ## We will use the Adam optimizer, which is, essentially, \n                             ## a slightly less stochastic version of stochastic gradient descent.\nfrom torch.utils.data import TensorDataset, DataLoader ## We'll store our data in DataLoaders\n\nimport lightning as L ## Lightning makes it easier to write, optimize and scale our code","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:11:43.166479Z","iopub.execute_input":"2024-07-23T00:11:43.167120Z","iopub.status.idle":"2024-07-23T00:12:02.563572Z","shell.execute_reply.started":"2024-07-23T00:11:43.167067Z","shell.execute_reply":"2024-07-23T00:12:02.562504Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Collecting lightning\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collecting lightning\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: PyYAML&lt;8.0,&gt;=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.5.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: fsspec&lt;2026.0,&gt;=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (2024.5.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.3.post0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: lightning-utilities&lt;2.0,&gt;=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.3.post0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy&lt;3.0,&gt;=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: packaging&lt;25.0,&gt;=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2+cpu)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: torch&lt;4.0,&gt;=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2+cpu)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.0.post0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: torchmetrics&lt;3.0,&gt;=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.0.post0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tqdm&lt;6.0,&gt;=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: typing-extensions&lt;6.0,&gt;=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.3.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.3.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (3.9.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (69.0.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities&lt;2.0,&gt;=0.10.0-&gt;lightning) (69.0.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&lt;25.0,&gt;=20.0-&gt;lightning) (3.1.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.13.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (3.13.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (1.13.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (1.13.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.2.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (3.2.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (3.1.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: attrs&gt;=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (23.2.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (6.0.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.9.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: frozenlist&gt;=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.4.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: aiosignal&gt;=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.3.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (4.0.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (2.1.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.3.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch&lt;4.0,&gt;=2.0.0-&gt;lightning) (1.3.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.6)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: idna&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (3.6)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Downloading lightning-2.3.3-py3-none-any.whl (808 kB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c890de962d644e98520b574b005a69a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Installing collected packages: lightning\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Installing collected packages: lightning\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Successfully installed lightning-2.3.3\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully installed lightning-2.3.3\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"token_to_id = {'what' : 0,\n               'is' : 1,\n               'statquest' : 2,\n               'awesome': 3,\n               '<EOS>' : 4, ## <EOS> = end of sequence\n              }\nid_to_token = dict(map(reversed, token_to_id.items()))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.564789Z","iopub.execute_input":"2024-07-23T00:12:02.565275Z","iopub.status.idle":"2024-07-23T00:12:02.570473Z","shell.execute_reply.started":"2024-07-23T00:12:02.565246Z","shell.execute_reply":"2024-07-23T00:12:02.569533Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"inputs = torch.tensor([[token_to_id[\"what\"], ## input #1: what is statquest <EOS> awesome\n                        token_to_id[\"is\"], \n                        token_to_id[\"statquest\"], \n                        token_to_id[\"<EOS>\"],\n                        token_to_id[\"awesome\"]], \n                       \n                       [token_to_id[\"statquest\"], # input #2: statquest is what <EOS> awesome\n                        token_to_id[\"is\"], \n                        token_to_id[\"what\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"awesome\"]]])\n\nlabels = torch.tensor([[token_to_id[\"is\"], \n                        token_to_id[\"statquest\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"awesome\"], \n                        token_to_id[\"<EOS>\"]],  \n                       \n                       [token_to_id[\"is\"], \n                        token_to_id[\"what\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"awesome\"], \n                        token_to_id[\"<EOS>\"]]])\n\ndataset = TensorDataset(inputs, labels) \ndataloader = DataLoader(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.571438Z","iopub.execute_input":"2024-07-23T00:12:02.571704Z","iopub.status.idle":"2024-07-23T00:12:02.593054Z","shell.execute_reply.started":"2024-07-23T00:12:02.571681Z","shell.execute_reply":"2024-07-23T00:12:02.591957Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class PositionEncoding(nn.Module):\n\n    def __init__(self, d_model=2, max_len=6):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n\n        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n\n        pe[:, 0::2] = torch.sin(position * div_term) \n        pe[:, 1::2] = torch.cos(position * div_term) \n        self.register_buffer('pe', pe) \n\n    def forward(self, word_embeddings):\n\n        return word_embeddings + self.pe[:word_embeddings.size(0), :] ","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.594333Z","iopub.execute_input":"2024-07-23T00:12:02.594614Z","iopub.status.idle":"2024-07-23T00:12:02.607207Z","shell.execute_reply.started":"2024-07-23T00:12:02.594591Z","shell.execute_reply":"2024-07-23T00:12:02.606307Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module): \n    def __init__(self, d_model=2):\n        super().__init__()\n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n\n        self.row_dim = 0\n        self.col_dim = 1\n\n    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n\n        q = self.W_q(encodings_for_q)\n        k = self.W_k(encodings_for_k)\n        v = self.W_v(encodings_for_v)\n\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n\n        if mask is not None:\n            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n\n        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n        attention_scores = torch.matmul(attention_percents, v)\n\n        return attention_scores","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.608402Z","iopub.execute_input":"2024-07-23T00:12:02.608700Z","iopub.status.idle":"2024-07-23T00:12:02.623675Z","shell.execute_reply.started":"2024-07-23T00:12:02.608674Z","shell.execute_reply":"2024-07-23T00:12:02.622682Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DecoderOnlyTransformer(L.LightningModule):\n    \n    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n        \n        super().__init__()\n        L.seed_everything(seed=42)\n        \n        self.we = nn.Embedding(num_embeddings=num_tokens, \n                               embedding_dim=d_model)     \n        \n        self.pe = PositionEncoding(d_model=d_model, \n                                   max_len=max_len)\n\n        self.self_attention = Attention(d_model=d_model)\n        \n        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n        \n        self.loss = nn.CrossEntropyLoss()\n        \n    \n    def forward(self, token_ids):\n                \n        word_embeddings = self.we(token_ids)        \n        position_encoded = self.pe(word_embeddings)\n        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)), device=self.device))\n        mask = mask == 0        \n        self_attention_values = self.self_attention(position_encoded, \n                                                    position_encoded, \n                                                    position_encoded, \n                                                    mask=mask)\n        residual_connection_values = position_encoded + self_attention_values\n        fc_layer_output = self.fc_layer(residual_connection_values)\n        \n        return fc_layer_output\n    \n    def configure_optimizers(self):\n        return Adam(self.parameters(), lr=0.1)\n    \n    def training_step(self, batch, batch_idx):\n        input_tokens, labels = batch # collect input\n        output = self.forward(input_tokens[0])\n        loss = self.loss(output, labels[0])\n                    \n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.624908Z","iopub.execute_input":"2024-07-23T00:12:02.625232Z","iopub.status.idle":"2024-07-23T00:12:02.635363Z","shell.execute_reply.started":"2024-07-23T00:12:02.625203Z","shell.execute_reply":"2024-07-23T00:12:02.634432Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Running model before training to see what it does\nmodel = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=6)\n\nmodel_input = torch.tensor([token_to_id[\"what\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"statquest\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input)\n\npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n\npredicted_ids = predicted_id\n\n# Now use a loop to predict output tokens until we get an <EOS> token.\nmax_length = 6\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n    \n# Now printout the predicted output phrase.\nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.638258Z","iopub.execute_input":"2024-07-23T00:12:02.638566Z","iopub.status.idle":"2024-07-23T00:12:02.783251Z","shell.execute_reply.started":"2024-07-23T00:12:02.638540Z","shell.execute_reply":"2024-07-23T00:12:02.782136Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"INFO: Seed set to 42\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Seed set to 42\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Seed set to 42\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Predicted Tokens:\n\n\t <EOS>\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = L.Trainer(max_epochs=30)\ntrainer.fit(model, train_dataloaders=dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:12:02.784477Z","iopub.execute_input":"2024-07-23T00:12:02.784807Z","iopub.status.idle":"2024-07-23T00:12:16.969686Z","shell.execute_reply.started":"2024-07-23T00:12:02.784779Z","shell.execute_reply":"2024-07-23T00:12:16.968685Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"INFO: GPU available: False, used: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"GPU available: False, used: False\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPU available: False, used: False\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"INFO: TPU available: False, using: 0 TPU cores\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"TPU available: False, using: 0 TPU cores\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TPU available: False, using: 0 TPU cores\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"INFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HPU available: False, using: 0 HPUs\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">HPU available: False, using: 0 HPUs\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"WARNING: Missing logger folder: /kaggle/working/lightning_logs\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[33mWARNING: Missing logger folder: /kaggle/working/lightning_logs\u001b[0m\u001b[33m\n\u001b[0m","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING: Missing logger folder: /kaggle/working/lightning_logs\n</span></pre>\n"},"metadata":{}},{"name":"stderr","text":"2024-07-23 00:12:05.548269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-23 00:12:05.548405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-23 00:12:05.696464: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO: \n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9718e04c75da402bbdb460a57ff6fc34"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"`Trainer.fit` stopped: `max_epochs=30` reached.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">`Trainer.fit` stopped: `max_epochs=30` reached.\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_input = torch.tensor([token_to_id[\"what\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"statquest\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input) \npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\npredicted_ids = predicted_id\n\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n        \nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:16:45.798137Z","iopub.execute_input":"2024-07-23T00:16:45.798904Z","iopub.status.idle":"2024-07-23T00:16:45.809948Z","shell.execute_reply.started":"2024-07-23T00:16:45.798859Z","shell.execute_reply":"2024-07-23T00:16:45.808511Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t awesome\n\t <EOS>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Asking the other question...\nmodel_input = torch.tensor([token_to_id[\"statquest\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"what\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input) \npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\npredicted_ids = predicted_id\n\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n        \nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T00:15:22.238529Z","iopub.execute_input":"2024-07-23T00:15:22.238928Z","iopub.status.idle":"2024-07-23T00:15:22.250018Z","shell.execute_reply.started":"2024-07-23T00:15:22.238895Z","shell.execute_reply":"2024-07-23T00:15:22.248939Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t awesome\n\t <EOS>\n","output_type":"stream"}]}]}